{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the documentation of NOOB project","text":"<p>NOOB (abbreviation for Not Only Observational Bundle) project consists of 3 key components. You can find the documentation here.</p> <ul> <li> <p>NOOBFRIEND Stands for Not Only Observational Bundle For Reduction, Inference, Extraction &amp; Navigation of Data: a python library built mainly on top of jwst, Pydantic, plotly, and etc. It provides several CLI applications to help with data reduction, analysis, management, and visualization. (1) </p> <ol> <li>Of course also for convenience of building noobackend and noobrowser. </li> </ol> </li> <li> <p>NOOBackend Stands for Not Only Organized Backend: a backend project built with FastAPI, SQLite, SQLModel, and Noobfriend as well.</p> </li> <li> <p>NOOBroswer Stands for Not Only Observational Broswer: a frontend application built by React, Tanstack Query, PixiJS, Chakra UI, and etc.</p> </li> </ul>"},{"location":"#main-purpose","title":"Main Purpose","text":"<p>The initial purpose is to develop</p> <ul> <li> <p>a convenient library to help manage the complex process of data reduction and analysis</p> </li> <li> <p>a well-arranged tool for visual inspection</p> </li> </ul> <p>for JWST/NIRCam WFSS and Image data.</p> <p>Maybe in the future I will extend it to include NIRSpec and IFU. (1)</p> <ol> <li> Possibly and hopefully.</li> </ol>"},{"location":"#who-may-want-to-use-it","title":"Who may want to use it","text":"<p>Of course everybody is welcome to use this project \ud83c\udf89.</p> <p>But you may want to try this project, if:</p> <ol> <li> <p>You are freshman of observational astronomy and not familiar with python. Then here is a noob friend (noob modifies friend, i.e., I am not an expert) for you. </p> </li> <li> <p>You want to paly with WFSS data, but get tired of reading mountains of documents.</p> </li> </ol> 3rd reason <p>You cannot tolerate running program with python&lt;3.9! </p>"},{"location":"#how-to-start","title":"How to start","text":"<p>If you are busy, just go through the key concept.</p> <p>Or you can read the step-by-step tutorial, which will provide a process that begins from 0.5. (1) </p> <ol> <li>It will try to be beginner-friendly, but I still assume you have some common sense of computer, such as how to search on the website, how to open the terminal, etc. </li> </ol>"},{"location":"#installation","title":"Installation?","text":"<p>Check the first part of tutorial!</p>"},{"location":"KeyConcepts/","title":"Overview","text":"<p>This Section show the key concepts of the package, and their full api documentation.</p>"},{"location":"KeyConcepts/navigation/","title":"JwstCover Class","text":""},{"location":"KeyConcepts/navigation/#jwstinfo-class","title":"JwstInfo Class","text":""},{"location":"StepByStepTutorial/","title":"Step-by-step Tutorial","text":"<p>In this tutorial, we will reduce FRESCO data with jwstnoobfriend, while I will introduce the key functions of this package along the way.</p> <p>I will show you the tutorial beyond this package as well.</p>"},{"location":"StepByStepTutorial/environment/","title":"Set Up Your Environment Variables","text":"<p>A good practice of setting up your environment is to create a <code>.env</code> file in the root of your project directory instead of hardcoding sensitive information directly into your code or exporting them in your global shell environment. </p> <p>In this package, I provide the <code>noobenv</code> CLI application to help you build and manage your <code>.env</code> file. The application is built using Typer, so don't forget to use '<code>--help</code>' to check the help message! </p>"},{"location":"StepByStepTutorial/environment/#check-the-help-message","title":"Check the help message","text":"uv run noobenv --help Usage: noobenv [OPTIONS] COMMAND [ARGS]...                                                                                                                     Commands for managing the .env file                                                                                                                           \u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\u2502 --install-completion          Install completion for the current shell.                                                                                    \u2502\u2502 --show-completion             Show completion for the current shell, to copy it or customize the installation.                                             \u2502\u2502 --help                        Show this message and exit.                                                                                                  \u2502\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\u2502 init     Initialize the .env file                                                                                                                          \u2502\u2502 append   Append folder information to the .env file                                                                                                        \u2502\u2502 check    Check whether the file paths in the .env file exist. The existing paths will be printed in green, and the non-existing paths will be printed in   \u2502\u2502          red.                                                                                                                                              \u2502\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f <p>As you can see, there are three commands available: <code>init</code>, <code>append</code>, and <code>check</code>.</p> <p>By using them one by one, we will finish setting up our environment variables \ud83d\ude0e.</p>"},{"location":"StepByStepTutorial/environment/#first-step-create-a-env-file","title":"First step: Create a <code>.env</code> file","text":"<p>The simplest way to create a <code>.env</code> file is to directly use the <code>init</code> command without any arguments.</p> noobenv initThe .env file has been written to /media/disk1/zchao/wfss/notebook/reduction/.env Don't forget to use <code>--help</code>! <p>You can use <code>noobenv init --help</code> to check the help message of each subcommand (here <code>init</code>) too!</p> <p>Now you can see a new file named <code>.env</code> in your project folder. You can open it and see the content is like this: .env<pre><code>CRDS_SERVER_URL=https://crds.stsci.edu\n# Path to the CRDS cache directory\nCRDS_PATH=\n\n# Root path for data storage\nDATA_ROOT_PATH= \n# Stage to start reduction, e.g., '1b'\nSTART_STAGE= \n</code></pre> You can fill in the values of these environment variables according to your needs . </p> <p>Before you proceed to the next step, don't leave any of these variables empty, as they are essential for the workflow .</p> <p>The values of these variables can be set by options in order that you can include them in your shell script. But now let's just fill them in manually.</p>"},{"location":"StepByStepTutorial/environment/#second-step-append-concrete-paths-to-the-env-file","title":"Second step: Append concrete paths to the <code>.env</code> file","text":"<p>The next step is to append the concrete paths of each steps to the <code>.env</code> file. You can use the <code>append</code> command to do this. And I highly recommend you to run it with the '<code>-n</code>' option, which will automatically generate the paths for you based on the \"stages\" provided.</p> uv run noobenv append -n 2a 2bi 2c 3aThe .env file has been updated with the new stage paths. <ul> <li>Note that if you don't use the '<code>-a</code>' option, every time you run the <code>append</code> command, it will overwrite the previously provided stages in the <code>.env</code> file. Again, see <code>noobenv append --help</code> or directly try it once you are confused with the behavior of the command .</li> <li>The first character of the stage name must be a number. So if you want to save any middle products, name the stage like <code>2bi</code> or <code>2bii</code>. The stage name is case-insensitive, but I recommend you to use lowercase letters for consistency \ud83e\uddd0.</li> <li>Don't be confused by the term <code>FILE_BOX_PATH</code>. This points to the path which will be the default path for the <code>FileBox.load()</code>. It is just for convenience. You can still load data from any other paths or rewrite this term based on what analysis you are doing.</li> </ul> Be careful if you are using terminal of VSCode\ud83d\udea8 <p>If you are using the terminal of VSCode, you may be able to directly use the <code>noobenv</code> command without the <code>uv run</code> prefix: <pre><code>$ noobenv append -n 2a 2bi 2c 3a\n</code></pre> However, when you create a new terminal in VSCode, it will automatically load the environment variables from the <code>.env</code> file, which will prevent us from updating the environment variables from the <code>.env</code> file.</p> <p>This is because out of the consideration of safety, we set the <code>override</code> option of the <code>load_dotenv</code> function to <code>False</code>. This means that the environment variables loaded from the <code>.env</code> file will not override the existing environment variables in the shell.</p> <p>If you don't want to see this behavior, the simplest way is to open a new terminal in VSCode after you make any changes to the environment variables in the <code>.env</code> file. </p>"},{"location":"StepByStepTutorial/environment/#third-step-check-and-prepare-the-folders","title":"Third step: Check and prepare the folders","text":"<p>Now you can check whether the paths in the <code>.env</code> file exist by using the <code>check</code> command. This will help you to ensure that there are no typos in the paths.</p> uv run noobenv check <p>In your terminal, the existing folders will be printed in green, and the non-existing folders will be printed in red.</p> <p>Once you have checked the paths, you can create the folders by running the following command:</p> uv run noobenv check -m"},{"location":"StepByStepTutorial/environment/#final-summary","title":"Final Summary","text":"<p>Now your <code>.env</code> file should look like this:</p> .env<pre><code>CRDS_SERVER_URL=https://jwst-crds.stsci.edu\n# Path to the CRDS cache directory\nCRDS_PATH=/path/to/workcrds_cache\n\n# Root path for data storage\nDATA_ROOT_PATH=/path/to/workPID_1895\n# Stage to start reduction, e.g., '1b'\nSTART_STAGE=1b\n\n# Path to the File Box tool\nFILE_BOX_PATH=/path/to/workPID_1895/noobox.json\n# Path to the auxiliary files directory\nAUXILIARY_PATH=/path/to/workPID_1895/auxiliary\n\n# Paths to save each level of the reduced data\n\n\nSTAGE_1B_PATH=/path/to/workPID_1895/stage1/1b\n\nSTAGE_2A_PATH=/path/to/workPID_1895/stage2/2a\n\nSTAGE_2B_PATH=/path/to/workPID_1895/stage2/2b\n\nSTAGE_2BI_PATH=/path/to/workPID_1895/stage2/2bi\n\nSTAGE_2C_PATH=/path/to/workPID_1895/stage2/2c\n\nSTAGE_3A_PATH=/path/to/workPID_1895/stage3/3a\n</code></pre>"},{"location":"StepByStepTutorial/fetch/","title":"Download JWST Data","text":"<p>In this part, we will download JWST data from the Multi-Mission Archive at Space Telescope (MAST). If you already have the data you want, you can skip this part.</p> <p>In this section, we will try to download all the data of a specific proposal id with a specific product level. As an example, we choose the FRESCO program (proposal id: 01895) and the product level '1b', which is the uncalibrated data.</p>"},{"location":"StepByStepTutorial/fetch/#visit-mast-jwst-portal","title":"Visit MAST JWST Portal","text":"<p>The most straightforward way to download JWST data is to visit the MAST JWST Portal and search for the data you want. </p>"},{"location":"StepByStepTutorial/fetch/#use-noobfetch","title":"Use noobfetch","text":"<p><code>jwstnoobfriend</code> provides a command line tool <code>noobfetch</code> to download JWST data, which is built by Typer.</p> <p>As a first step, try to see the help message of <code>noobfetch</code> by running <code>noobfetch --help</code> in your terminal. You should see something like this:</p> uv run noobfetch --help  Usage: noobfetch [OPTIONS] COMMAND [ARGS]...                                                                                                                              Check and retrieve JWST data from MAST.                                                                                                                                  \u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\u2502 --install-completion          Install completion for the current shell.                                                                                               \u2502\u2502 --show-completion             Show completion for the current shell, to copy it or customize the installation.                                                        \u2502\u2502 --help                        Show this message and exit.                                                                                                             \u2502\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\u2502 check      Old version of the check command. In this version, the retrieval is done by astroquery. And for the speed, we assume every dataset of the same instrument  \u2502\u2502            has the same suffix, which may not be true in some cases. Use retrieve command instead.                                                                    \u2502\u2502 retrieve   Check the JWST data of given proposal id from MAST.                                                                                                        \u2502\u2502 download   Download the JWST data of given products list.                                                                                                             \u2502\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f <p>As the help message suggests, basically you only need to run the subcommands <code>retrieve</code> and <code>download</code> to check and download the JWST data.</p>"},{"location":"StepByStepTutorial/fetch/#get-the-product-list","title":"Get the product list","text":"<p>First we need to prepare a product list. You can run:</p> uv run noobfetch retrieve 01895 -l 1b <ul> <li>The proposal id should be 5 digits long, so if you want to retrieve data from a proposal id like <code>1895</code>, you should use <code>01895</code> instead.</li> <li>The <code>-l</code> option specifies the product level, e.g., <code>1b</code>.</li> <li>The <code>--help</code> option is always available, so you can check the help message to get more flexible options.</li> </ul> Why it is faster to use <code>noobfetch</code>? <p>The <code>noobfetch</code> uses asynchronous requests to retrieve the data. </p> <p>I don't know why if we sent the FileSetIDs to the MAST API, it will take a long time to get the response. So I use the asynchronous requests and only send one filesetid in one request, which speeds up the retrieval process significantly.</p> <p>After the command is executed, you should find the product list in a file named <code>products.json</code>. You can open it and do some filtering before downloading the data. But in this tutorial, we will just download all the products in the FRESCO program.</p>"},{"location":"StepByStepTutorial/fetch/#download-the-data","title":"Download the data","text":"<p>If you followed the Environment Variables part, you can directly run:</p> uv run noobfetch download products.json <p>The files will be downloaded to the path specified by the <code>STAGE_1B_PATH</code> in the <code>.env</code> file if you set the <code>START_STAGE</code> to <code>1b</code>.</p> <p>Otherwise, you need to specify the folder to save the downloaded data by using the <code>-o</code> option. See the help message by running <code>noobfetch download --help</code> for more details.</p> Use <code>tmux</code> or <code>screen</code> to run the command in the background <p>If you are running the command on a remote server, you can use <code>tmux</code> or <code>screen</code> to run the command in the background. This way, you can close the terminal without interrupting the download process \ud83d\ude0b. This method can be applied when you are executing any long-running command in the terminal.</p> screentmux <pre><code>$ screen -S download # or any other name you like\n# Now you are in a new screen session\n$ uv run noobfetch download products.json\n# To detach from the screen session, press `Ctrl + A`, then `D`\n# When you feel the download is finished, you can reattach to the session by running:\n$ screen -r download\n</code></pre> <pre><code>$ tmux new -s download\n# Now you are in a new tmux session\n$ uv run noobfetch download products.json\n# To detach from the tmux session, press `Ctrl + B`, then `D`\n# When you feel the download is finished, you can reattach to the session by running:\n$ tmux attach -t download\n</code></pre>"},{"location":"StepByStepTutorial/fetch/#use-astroquery","title":"Use astroquery","text":"<p>You can also use the <code>astroquery</code> package.</p> Download data with astroquery<pre><code>from astroquery.mast.missions import MastMissionsClass\n\nmission = MastMissionsClass(mission=\"jwst\")\nproposal_id = \"01895\"  # FRESCO program\nproduct_level = \"1b\"  # Uncalibrated data\nprogram_query = mission.query_criteria( # type: ignore\n    program=proposal_id,\n    productLevel=product_level\n)\nproduct_list = mission.get_product_list(program_query)\n</code></pre> <p>But the highlighted line seems to take a super long time to execute . You can refer the astroquery documentation to learn how to download the data with <code>astroquery</code>.</p>"},{"location":"StepByStepTutorial/installation/","title":"How to install it","text":"<p>First, open a terminal window and start your shell. I am using fish. (1) </p> <ol> <li>Fish \ud83d\udc1f is a morden shell with smooth experience of auto completion, highly recommend you to have a try \ud83d\ude09\uff01</li> </ol> uvpip fish<pre><code>uv add jwstnoobfriend\n</code></pre> fish<pre><code>pip install jwstnoobfriend\n</code></pre> use uv for package management <p>Wait\ud83e\udd14, what is uv here? Personally, I think it is a python version of npm (javascript/typescript) or cargo (rust). </p> <p>Different from anaconda, you will not have a virtual environment globaly, but each workspace (folder) will have its own virtual environment. This is super benifitial when you plan to output the dependencies of your project. Also, you don't have to maintain a lengthy list of anaconda virtual environment to avoid potential pacakge version conflict.</p> <p>The following steps are a brief tutorial on how to use uv. Safely skip it if you are already familiar with uv or you want to use old-school <code>pip</code>.</p>"},{"location":"StepByStepTutorial/installation/#install-uv","title":"Install uv","text":"<p>Please refer to the uv installation guide for more details. Here I just list the necessary steps so that you don't have to jump around.</p> macOS and LinuxWindows fish<pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre> powershell<pre><code>powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre> <p>Note that I don't have experience with Windows System, so if you encounter any issues, please refer to the uv installation guide for troubleshooting. And for the following steps, I will only show the commands for macOS and Linux.</p>"},{"location":"StepByStepTutorial/installation/#initialize-a-working-folder","title":"Initialize a working folder","text":"<p>After you have installed uv, you can create a new working folder and initialize it with uv.</p> uv init project_nameInitialized project `project_name` at `/Users/zero/project_name`cd project_name <p>This will create a new folder named <code>project_name</code> and a virtual environment inside it.</p> tldr <p>To get the help of uv, of course you can use <code>uv --help</code>, or <code>uv init --help</code> to get the help of subcommands. But I found uv and its subcommands have <code>tldr</code> documentation. So use <code>tldr uv</code> or <code>tldr uv init</code> will give you a concise summary of the command. But ensure you have installed tldr first.</p>"},{"location":"StepByStepTutorial/installation/#use-notebook-in-vscode-with-uv","title":"Use notebook in vscode with uv","text":"<p>For uv, <code>uv add package_name</code> command is almost the same as <code>pip install package_name</code>, but I would like to suggest to use <code>uv add --dev package_name</code> to install the packages like <code>jupyter</code>, <code>ipykernel</code>, etc. </p> why and when to use <code>--dev</code>? <p>This is because these packages are only used by you for development, and for people who try to reproduce your work, they don't need to use these packages. A simple way to distinguish whether you should use <code>--dev</code> or not is to check whether you have to import the package in your code. </p> <p>For example, I think for most people, they never import <code>ipykernel</code> in their code, so you should use <code>uv add --dev ipykernel</code> to install it. But for <code>numpy</code>, you should use <code>uv add numpy</code> to install it, because you will import it in your code.</p> uv add --dev jupyter ipykernelInstalled 2 packages in 0.1s+ jupyter+ ipykernel <p>Make sure you have installed the necessary vscode extentions for jupyter notebook (search jupyter in the extension marketplace).</p> <p>Then create a file with the suffix <code>.ipynb</code>, and open it with vscode. You will see a button to select the kernel.</p> <p></p> <p>If your vscode workspace is the project folder you just created, you will directly see a recommended kernel and choose it. If not, select the file <code>project_name/.venv/bin/python</code> as the kernel.</p>"},{"location":"StepByStepTutorial/installation/#install-packages","title":"Install packages","text":"<p>Then you can install the packages you need!</p> uv add jwstnoobfriendInstalled 1 package in 0.1sjwstnoobfriend <p>Note that you can start to run some code in the notebook and then try to use <code>uv add</code> to install a new package. Then import it in the notebook. Try the same thing with the kernel to be an anaconda environment (by using <code>pip install</code>).</p> <p>You will find that you don't have to restart the kernel to use the newly installed package in uv, but not in anaconda. Another reason to try uv \ud83d\ude0a!</p> remove a package <p>If you want to remove a package from your dependencies, you can use <code>uv remove package_name</code> command. </p>"},{"location":"StepByStepTutorial/installation/#a-brief-summary","title":"A brief summary","text":"<ul> <li><code>uv init</code> to initialize a new project folder with a virtual environment. </li> <li><code>uv add package_name</code> to install a package in the virtual environment. use <code>--dev</code> to install a package only for development.</li> <li><code>uv remove package_name</code> to remove a package from the virtual environment.</li> </ul>"},{"location":"StepByStepTutorial/reduction/","title":"Be Ready?","text":"<p>Before we proceed, please ensure you have:</p> <ul> <li>Downloaded all the necessary data files.</li> <li>Set up the environment variables as described in the Environment Variables section.</li> </ul> <p>If everything is ready, we can start reducing the data using the JWST official pipeline with the help of our NOOBFRIEND package !</p>"},{"location":"StepByStepTutorial/reduction/stage1/","title":"Noobscript: your noobfriend for JWST data reduction script","text":"<p>We use <code>toml</code> format to write configuration parameters for the pipeline. The <code>toml</code> file can be loaded as <code>dict</code>, and the parameters are stored in a more arranged way, making it easier to manage and modify them.</p> <p>In this package, we provide a CLI called noobscript to help generate the <code>toml</code> configuration files and <code>python</code> scripts for different stages of the JWST pipeline.</p> <ul> <li>If the output products are in stage2, you can use the <code>noobscript stage2</code> command to generate the configuration file and script.</li> <li>If the product is 3a, you can use the subcommand <code>noobscript stage3</code>.</li> </ul> <p>In the following section, you will find how to use these commands .</p>"},{"location":"StepByStepTutorial/reduction/stage1/#prepare-your-noobox","title":"Prepare your noobox","text":"<p>Before the reduction, we need to initialize our noobox. It can be simply done by running: <pre><code>from jwstnoobfriend.navigation import FileBox\n\nfilebox = FileBox.init_from_folder()\nfilebox.save()\n</code></pre></p> No Parameters needed? <p>The <code>init_from_folder</code> method will automatically fill in the parameters based on the environment variables. You can also provide parameters manually if needed. </p>"},{"location":"StepByStepTutorial/reduction/stage1/#stage-1-from-uncalibrated-to-rate","title":"Stage 1: From uncalibrated to rate","text":"<p>In this reduction step, the pipeline will fit the slope of uncalibrated files, and obtain the rate files. In our example, <code>rate</code> files and <code>rateint</code> files are essentially the same. Additionally, we don't have to distinguish grism and clear image files.</p> <p>First, use <code>noobscript</code> as follows:</p> uv run noobscript stage2 2a -p pid1895 <p>Here, <code>2a</code> is the command argument standing for output stage, which is needed to load corresponding template; <code>-p</code> stands for prefix of the saved script and configuration file name. (1) </p> <ol> <li>You can always check the parameter meaning by typing <code>uv run noobscript stage2 --help</code>.</li> </ol> <p>Then two files will be generated in your current folder if you don't specify the output directory: pid1895_all_2a.toml<pre><code># The setup for reduction stage 1b-&gt;2a\n\n# whether save results\nsave_results = true\n\noutput_dir = \"/media/disk1/zchao/icrrhome/zchao/noobfriend/PID_1895/stage2/2a\"\n\n\n[steps.jump]\nsave_results = true\nmaximum_cores = 'half'\n# whether the jump step will expand the number of pixels that are flagged around large cosmic ray events\nexpand_large_events = true\n# A boolean value that if True requires that there are saturated pixels within the enclosed jump circle.\nsat_required_snowball = false\n# A multiplicative factor applied to the enclosing ellipse for snowballs. This larger area will have all pixels flagged as having a jump.\nexpand_factor = 2\n\n[steps.clean_flicker_noise]\n# This step will be skipped by default.\nskip = false\n# The background method is fitting with a low-resolution model via Background2D\nbackground_method = \"model\"\nbackground_box_size = [64, 64]\n</code></pre></p> <p>Here I give several setup based on my own experience, you can change them as needed.</p> pid1895_1b_2a.py<pre><code>from jwstnoobfriend.navigation import FileBox\nfrom jwstnoobfriend.utils.environment import load_environment # To load environment variables\nfrom jwstnoobfriend.utils.display import console # Make sure you are use the same console instance.\nimport os # To access environment variables\n\n## In case you need to do parallel processing, but it is not necessary because the bottleneck is not CPU-bound tasks.\nfrom concurrent.futures import ProcessPoolExecutor\n\nimport logging\n\n## To mute noisy logging messages from the JWST pipeline\n\n\nCRDS_logger = logging.getLogger('CRDS')\n\nfor handler in CRDS_logger.handlers[:]:\n    CRDS_logger.removeHandler(handler)\n\nCRDS_logger.propagate = False\n\n\nstpipe_logger = logging.getLogger('stpipe')\n\nfor handler in stpipe_logger.handlers[:]:\n    stpipe_logger.removeHandler(handler)\n\nstpipe_logger.propagate = False\n\n\njwst_logger = logging.getLogger('jwst')\n\nfor handler in jwst_logger.handlers[:]:\n    jwst_logger.removeHandler(handler)\n\njwst_logger.propagate = False\n\n### The logger name may change in the future JWST pipeline versions.\n### You can always check the logger names and mute them accordingly.\n\n\nload_environment()\nfilebox = FileBox.load()\n\n## Load toml configuration file\nimport tomllib\nwith open(\"/media/disk1/zchao/wfss/notebook/reduction_with_noob/pid1895_all_2a.toml\", \"rb\") as f:\n    config = tomllib.load(f)\n\n## Reduction process\nfrom jwst.pipeline import Detector1Pipeline\n\ndef reduce_info(info):\n\n    log_filename = f\"./.log/1b_2a/{info.basename}.log\"\n    file_handler = logging.FileHandler(log_filename, mode='w')\n    file_handler.setLevel(logging.INFO)\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    file_handler.setFormatter(formatter)\n\n\n\n\n    try:\n        ## Run the pipeline with the config loaded from the toml file\n        result = Detector1Pipeline.call(info['1b'].filepath, **config)\n\n        logging.getLogger('processing').addHandler(file_handler)\n        logging.getLogger('processing').info(f\"Successfully processed {info.basename}\")\n    except Exception as e:\n        logging.getLogger('processing').addHandler(file_handler)\n        logging.getLogger('processing').error(f\"Error processing {info.basename}: {str(e)}\")\n        raise\n    finally:\n\n        file_handler.close()\n    return True \n\ndef main():\n\n\n    console.print(\"[bold green]Starting reduction process...[/bold green]\")\n    console.print(f\"Using 1 processes\")\n    console.print(f\"Configuration loaded from: /media/disk1/zchao/wfss/notebook/reduction_with_noob/pid1895_all_2a.toml\")\n\n    with ProcessPoolExecutor(max_workers=1) as executor:\n        futures = [executor.submit(reduce_info, info) for info in filebox.info_list]\n\n        successful = 0\n        failed = 0\n\n        for i, future in enumerate(futures):\n            try:\n                future.result()\n                successful += 1\n                console.print(f\"[green] ({i+1}/{len(filebox.info_list)}) Successfully processed: {filebox.info_list[i].basename}[/green]\")\n            except Exception as e:\n                failed += 1\n                console.print(f\"[red] ({i+1}/{len(filebox.info_list)}) Error processing {filebox.info_list[i].basename}: {str(e)}[/red]\")\n\n    console.print(f\"[bold green]Reduction process completed![/bold green]\")\n    console.print(f\"[bold green]Successful: {successful}[/bold green]\")\n    console.print(f\"[bold red]Failed: {failed}[/bold red]\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Here I tried to add some comments to help you understand the code. You can modify the code as needed.</p>"},{"location":"StepByStepTutorial/reduction/stage2-CLEAR/","title":"Why I need FileBox?","text":"<p>You may want to know why this package provides a class called <code>FileBox</code> to help manage files. I will show some convenience of using <code>FileBox</code> in the following sections.</p>"},{"location":"StepByStepTutorial/reduction/stage2-CLEAR/#stage-2-for-clear-images-from-rate-to-cal","title":"Stage 2 for CLEAR Images: from rate to cal","text":"<p>Based on the official workflow, we need to proceed the CLEAR image reduction first, and then use the results to do the Grism reduction.</p> <p>In this step, we will use the <code>noobscript</code> command again.</p> uv run noobscript stage 2b -p pid1895 <p>Take a look at the generated <code>toml</code> file:</p> pid1895_all_2b.toml<pre><code># The setup for reduction stage 2a-&gt;2b\n\n# whether save results\nsave_results = true\n\noutput_dir = \"/media/disk1/zchao/icrrhome/zchao/noobfriend/PID_1895/stage2/2b\"\n\n\n[steps.resample]\nskip = true\n</code></pre> <p>As always, you can modify the parameters as needed. Here I just skip the <code>resample</code> step, because later we will combine the dithered images.</p> <p>Here is the generated script:</p> pid1895_2a_2b.py<pre><code>from jwstnoobfriend.navigation import FileBox\nfrom jwstnoobfriend.utils.environment import load_environment # To load environment variables\nfrom jwstnoobfriend.utils.display import console # Make sure you are use the same console instance.\nfrom jwstnoobfriend.reduction import nircam_1f_noise # This is a commonly used simple way to model 1/f noise for NIRCam data.\nimport os # To access environment variables\n\n## In case you need to do parallel processing, but it is not necessary because the bottleneck is not CPU-bound tasks.\nfrom concurrent.futures import ProcessPoolExecutor\nimport logging\n\n## To mute noisy logging messages from the JWST pipeline\n\n\nCRDS_logger = logging.getLogger('CRDS')\n\nfor handler in CRDS_logger.handlers[:]:\n    CRDS_logger.removeHandler(handler)\n\nCRDS_logger.propagate = False\n\n\nstpipe_logger = logging.getLogger('stpipe')\n\nfor handler in stpipe_logger.handlers[:]:\n    stpipe_logger.removeHandler(handler)\n\nstpipe_logger.propagate = False\n\n\njwst_logger = logging.getLogger('jwst')\n\nfor handler in jwst_logger.handlers[:]:\n    jwst_logger.removeHandler(handler)\n\njwst_logger.propagate = False\n\n### The logger name may change in the future JWST pipeline versions.\n### You can always check the logger names and mute them accordingly.\n\n\nload_environment()\nfilebox = FileBox.load()\nclearbox = filebox.select(condition={'pupil': ['CLEAR']})\n\n## Load toml configuration file\nimport tomllib\nwith open(\"/media/disk1/zchao/wfss/notebook/reduction_with_noob/pid1895_clear_2b.toml\", \"rb\") as f:\n    config = tomllib.load(f)\n\n## Reduction process\nfrom jwst.pipeline import Image2Pipeline\n\ndef reduce_info(info):\n\n    log_filename = f\"./.log/2a_2b/{info.basename}.log\"\n    file_handler = logging.FileHandler(log_filename, mode='w')\n    file_handler.setLevel(logging.INFO)\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    file_handler.setFormatter(formatter)\n\n\n\n\n    try:\n        ## Run the pipeline with the config loaded from the toml file\n        datamodel = info['2a'].datamodel\n        datamodel.data = datamodel.data - nircam_1f_noise(info, stage = '2a')\n        result = Image2Pipeline.call(datamodel, **config)\n\n        logging.getLogger('processing').addHandler(file_handler)    \n        logging.getLogger('processing').info(f\"Successfully processed {info.basename}\")\n    except Exception as e:\n        logging.getLogger('processing').addHandler(file_handler)\n        logging.getLogger('processing').error(f\"Error processing {info.basename}: {str(e)}\")\n        raise\n    finally:\n\n        file_handler.close()\n    return True\n\ndef main():\n\n\n    console.print(\"[bold green]Starting reduction process...[/bold green]\")\n    console.print(f\"Using 1 processes\")\n    console.print(f\"Configuration loaded from: /media/disk1/zchao/wfss/notebook/reduction_with_noob/pid1895_clear_2b.toml\")\n\n    with ProcessPoolExecutor(max_workers=1) as executor:\n        futures = [executor.submit(reduce_info, info) for info in clearbox.infos]\n        successful = 0\n        failed = 0\n\n        for i, future in enumerate(futures):\n            try:\n                future.result()\n                successful += 1\n                console.print(f\"[green] ({i+1}/{len(filebox.info_list)}) Successfully processed: {filebox.info_list[i].basename}[/green]\")\n            except Exception as e:\n                failed += 1\n                console.print(f\"[red] ({i+1}/{len(filebox.info_list)}) Error processing {filebox.info_list[i].basename}: {str(e)}[/red]\")\n\n    console.print(f\"[bold green]Reduction process completed![/bold green]\")\n    console.print(f\"[bold green]Successful: {successful}[/bold green]\")\n    console.print(f\"[bold red]Failed: {failed}[/bold red]\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Additionally, we provide the script <code>pid1895_2bi_3a.py</code> for sky subtraction if you run:</p> uv run noobscript stage 2bi -p pid1895 source code of pid1895_2b_2bi pid1895_2b_2bi.py<pre><code>from jwstnoobfriend.navigation import FileBox, JwstInfo\nfrom jwstnoobfriend.utils.environment import load_environment # To load environment variables\nfrom jwstnoobfriend.utils.display import console # Make sure you are use the same console instance.\nimport os # To access environment variables\n\n## In case you need to do parallel processing, but it is not necessary because the bottleneck is not CPU-bound tasks.\nfrom concurrent.futures import ProcessPoolExecutor\nfrom pathlib import Path\n\nload_environment()\nclear_box = FileBox.load(suffix = \"clear\")\n## Reduction process\n## This is a custom reduction step for subtracting the sky background.\ndef reduce_info(info: JwstInfo):\n    try:\n        datamodel = info['2b'].datamodel\n        datamodel.data = datamodel.data - info['2b'].background # Subtract the background\n        output_dir = Path(os.getenv('STAGE_2BI_PATH', './stage_2bi'))\n        if not output_dir.exists():\n            raise FileNotFoundError(f\"Output directory {output_dir} does not exist.\")\n        datamodel.write(output_dir / info['2b'].filepath.name, overwrite=True)\n\n    except Exception as e:\n        console.print(f\"[red]Error processing {info.basename}: {str(e)}[/red]\")\n        raise\n    return True\n\ndef main():\n    with ProcessPoolExecutor(max_workers=1) as executor:\n        futures = [executor.submit(reduce_info, info) for info in clear_box.info_list]\n        successful = 0\n        failed = 0\n\n        for i, future in enumerate(futures):\n            try:\n                result = future.result()\n                successful += 1\n                console.print(f\"[green]Successfully processed {clear_box.info_list[i].basename}[/green]\")\n            except Exception as e:\n                failed += 1\n                console.print(f\"[red]Failed to process {clear_box.info_list[i].basename}: {str(e)}[/red]\")\n\n        console.print(f\"[yellow]Summary: {successful} succeeded, {failed} failed[/yellow]\")\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>After the <code>Image2Pipeline</code> step, you can interactively check the footprints of your reduced images by using the following code:</p> Check footprints of reduced images<pre><code>from jwstnoobfriend.navigation import FileBox\nfile_box = FileBox.load(suffix='clear')\nfile_box.show_footprints()\n</code></pre> <p>Here, we show FRESCO footprints as an example:</p>"},{"location":"StepByStepTutorial/reduction/stage2-GRISM/","title":"GRISM image is also image","text":"<p>Basically, the reduction of GRISM image is similar to CLEAR image. The main difference is that we skip the <code>photom</code> step in Image2Pipeline.</p>"},{"location":"StepByStepTutorial/reduction/stage2-GRISM/#stage-2-for-grism-images-from-rate-to-cal","title":"Stage 2 for GRISM Images: from rate to cal","text":"<p>Everything is the same as CLEAR image stage2, except that we need to add one line in the <code>toml</code> file to skip the photom step.</p> pid1895_all_2b_grism.toml<pre><code># The setup for reduction stage 2a-&gt;2b\n\n# whether save results\nsave_results = true\n\noutput_dir = \"/media/disk1/zchao/icrrhome/zchao/noobfriend/PID_1895/stage2/2b\"\n\n\n[steps.resample]\nskip = true\n[steps.photom]\nskip = true\n</code></pre> <p>Well Done! Now all the files are production ready! Move on with our NooBackend and NooBrowser to explore the data :D</p>"},{"location":"StepByStepTutorial/reduction/stage3-CLEAR/","title":"Combination is not easy","text":"<p>Combining dithered images is not as straightforward as running a single command. This is because JWST's dithered observations often involve complex patterns and varying observational conditions that need to be carefully accounted for during the combination process.</p> <p>One of the main challenges is aligning the images accurately. Usually this is done by using Gaia catalog. However, in many cases, the field stars are too sparse to get a good alignment. In such cases, you may need to use some galaxy catalog for alignment. Here I choose to use CANDELS catalog for alignment but unfortunately, this cannot be easily generalized to other fields.</p>"},{"location":"StepByStepTutorial/reduction/stage3-CLEAR/#stage-3-for-clear-images-from-cal-to-i2d","title":"Stage 3 for CLEAR Images: from cal to i2d","text":"<p>In this step, I will directly show you the script</p> pid1895_2bi_3a.py<pre><code>import os\nimport numpy as np\nimport tomllib\nimport logging\nfrom pathlib import Path\nimport time\n\nfrom jwstnoobfriend.navigation import FileBox\nfrom jwstnoobfriend.utils.environment import load_environment\nfrom jwstnoobfriend.utils.display import console\nload_environment()\nimport jwst\nimport crds\nconsole.print(f\"JWST version: {jwst.__version__}\")\n\n\n# Get potential loggers\ntweakwcs_logger = logging.getLogger('tweakwcs')\ncrds_logger = logging.getLogger('CRDS')\nstpipe_logger = logging.getLogger('stpipe')\nstcal_logger = logging.getLogger('stcal')\njwst_logger = logging.getLogger('jwst')\n\n# Remove handlers\nfor handler in tweakwcs_logger.handlers[:]:\n    tweakwcs_logger.removeHandler(handler)\nfor handler in crds_logger.handlers[:]:\n    crds_logger.removeHandler(handler)\nfor handler in stpipe_logger.handlers[:]:\n    stpipe_logger.removeHandler(handler)\nfor handler in jwst_logger.handlers[:]:\n    jwst_logger.removeHandler(handler)\nfor handler in stcal_logger.handlers[:]:\n    stcal_logger.removeHandler(handler)\n\ntweakwcs_logger.propagate = False\ncrds_logger.propagate = False\nstpipe_logger.propagate = False\njwst_logger.propagate = False\nstcal_logger.propagate = False\n\n# In each grouped FileBox, we will combine them to create association file\nclear_box = FileBox.load(os.environ['DATA_ROOT_PATH'] + '/noobox_clear.json')  # type: ignore\ngrouped_box_list = clear_box.group_by_pointing()\nfrom collections import defaultdict\ngroups_dict = defaultdict(list)\nfor box in grouped_box_list:\n    filesetnames_key = tuple(sorted(box.filesetnames)+[box[0].detector[:4]])\n    groups_dict[filesetnames_key].append(box)\n\ngroups_for_reduction = list(groups_dict.values())\nfor group in groups_for_reduction:\n    for j in range(1, len(group)):\n        group[0].merge(group[j])\ngroups = [g[0] for g in groups_for_reduction]\n\nwith open(\"pipeline_setup_3a.toml\", \"rb\") as f:\n    config = tomllib.load(f)\n\nstage_3a_path = Path(os.environ['STAGE_3A_PATH'])\n\nfrom jwst.associations import asn_from_list\nfrom jwst.associations.lib.rules_level3 import DMS_Level3_Base\nfrom jwst.pipeline import Image3Pipeline\n\nimport pyvo as vo\nimport pandas as pd\nfrom astropy.table import Table\nfrom pathlib import Path\nrefcat = Table()\nsvc = vo.dal.TAPService(\"https://mast.stsci.edu/vo-tap/api/v0.1/candels\")\n\ncat = svc.search(\"\"\"\nSELECT * FROM dbo.candels_master_view\nWHERE field='GOODS-N' OR field='GOODS-S'\n\"\"\").to_table() #type: ignore\nrefcat['RA'] = cat['RA']\nrefcat['DEC'] = cat['DEC']\nrefcat.write('candels_master_view_ecsv.ecsv', format='ascii.ecsv', overwrite=True)\n\ndef reduce(\n    group: FileBox\n):\n    time1 = time.time()\n\n    filesetnames = group.filesetnames\n    obs_visit_all = [f.split('_')[0] for f in filesetnames]\n    obs_visit_unique = list(set(obs_visit_all))\n    if len(obs_visit_unique) != 1:\n        print(f\"Multiple observation visits found {filesetnames}\")\n    obs_visit = obs_visit_unique[0]\n    mid_seq_all = [f.split('_')[1] for f in filesetnames]\n    mid_seq_unique = sorted(list(set(mid_seq_all)))\n    product_name = obs_visit + '_' + '+'.join(mid_seq_unique) + '_' + group[0].filter + '_' + group[0].detector[:4]\n\n    # Temporary step to skip existing file:\n    #if (stage_3a_path / (product_name+'_i2d.fits')).exists():\n    #    console.print(f\"Skipping existing product {product_name}\")\n    #    return\n\n    log_filename = f\"./log/3a/{product_name}.log\"\n    file_handler = logging.FileHandler(log_filename)\n    file_handler.setLevel(logging.INFO)\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n    file_handler.setFormatter(formatter)\n\n    for logger in [tweakwcs_logger, crds_logger, stpipe_logger, jwst_logger, stcal_logger]:\n        logger.addHandler(file_handler)\n        logger.setLevel(logging.INFO)\n\n    # Reduce:\n    try:\n        association = asn_from_list.asn_from_list(\n            [info['2bi'].filepath.__str__() for _, info in group],\n            rule=DMS_Level3_Base,\n            product_name=product_name\n        )\n        association['asn_type'] = 'image3'\n        association['program'] = group[0]['2b'].meta.observation.program_number\n        _, asn_serialized = association.dump(format=\"json\")\n        asn_path = Path(\"./asn\") / (product_name + \"_asn.json\")\n        with open(asn_path, \"w\") as asn_file:\n            asn_file.write(asn_serialized)\n        time2 = time.time()\n        i2d_result = Image3Pipeline.call(\n            str(asn_path),\n            **config\n        )\n        time3 = time.time()\n        # Show time in mins\n        console.print(f\"Finished reducing {product_name} in {(time2-time1)/60.:.1f} mins (setup) + {(time3-time2)/60.:.1f} mins (running)\")\n    except Exception as e:\n        with open(\"log/3a_errors.log\", \"a\") as ef:\n            ef.write(f\"Error processing group {filesetnames}: {e}\\n\")\n    finally:\n        for logger in [tweakwcs_logger, crds_logger, stpipe_logger, jwst_logger, stcal_logger]:\n            logger.removeHandler(file_handler)\n    return True\n\n\nfrom jwstnoobfriend.utils.display import track\n\ndef main():\n    for group in track(groups):\n        reduce(group)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Unfortunately, the automatically generated catalogs in <code>pyvo</code> do not have good quality for alignment. Therefore, you have to manually find a good catalog for alignment by yourself.</p>"}]}